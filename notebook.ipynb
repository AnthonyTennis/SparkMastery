{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Spark Mastery\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# make sure your run the cell above before running this\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created with 500,000 lines.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Define the number of lines and the headers\n",
    "num_lines = 500000\n",
    "headers = ['jobId', 'sendingTeam', 'status', 'startDate', 'endDate']\n",
    "\n",
    "# Status options for the 'status' field\n",
    "status_options = ['Pending', 'In Progress', 'Completed', 'Failed']\n",
    "sending_team_options = ['MindOvermatter', 'JuiceBox', 'AndersonSquad', 'Distributo']\n",
    "\n",
    "# Function to generate a random date after 2000\n",
    "def random_date():\n",
    "    start_date = datetime(2000, 1, 1)\n",
    "    end_date = datetime.now()\n",
    "    time_between_dates = end_date - start_date\n",
    "    days_between_dates = time_between_dates.days\n",
    "    random_number_of_days = random.randrange(days_between_dates)\n",
    "    return start_date + timedelta(days=random_number_of_days)\n",
    "\n",
    "# Creating and writing to the CSV file\n",
    "with open('jobs_data.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # Writing the header\n",
    "    writer.writerow(headers)\n",
    "    \n",
    "    # Writing the data rows\n",
    "    for i in range(1, num_lines + 1):\n",
    "        # Generate a random status\n",
    "        status = random.choice(status_options)\n",
    "        sending_team = random.choice(sending_team_options)\n",
    "        \n",
    "\n",
    "        # Generate a random start date\n",
    "        start_date = random_date().strftime('%Y-%m-%d')\n",
    "\n",
    "        # Generate an end date for 'Completed' or 'Failed' jobs\n",
    "        end_date = ''\n",
    "        if status in ['Completed', 'Failed']:\n",
    "            end_date = random_date().strftime('%Y-%m-%d')\n",
    "\n",
    "        # Write the row\n",
    "        writer.writerow([f\"Job{i}\", sending_team, status, start_date, end_date])\n",
    "\n",
    "# Inform the user that the file has been created\n",
    "print('CSV file created with 500,000 lines.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 46:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.head of DataFrame[jobId: string, sendingTeam: string, status: string, startDate: date, endDate: date]>\n",
      "['jobId', 'sendingTeam', 'status', 'startDate', 'endDate']\n",
      "+-----+--------------+-----------+----------+----------+\n",
      "|jobId|   sendingTeam|     status| startDate|   endDate|\n",
      "+-----+--------------+-----------+----------+----------+\n",
      "| Job1|    Distributo|    Pending|2001-09-22|      NULL|\n",
      "| Job2|      JuiceBox|    Pending|2007-05-23|      NULL|\n",
      "| Job3|MindOvermatter|    Pending|2018-08-27|      NULL|\n",
      "| Job4|    Distributo|  Completed|2020-05-21|2014-01-05|\n",
      "| Job5|MindOvermatter|  Completed|2005-12-30|2013-02-11|\n",
      "| Job6| AndersonSquad|     Failed|2007-07-23|2015-12-02|\n",
      "| Job7|      JuiceBox|     Failed|2019-01-03|2003-12-07|\n",
      "| Job8|    Distributo|    Pending|2019-12-10|      NULL|\n",
      "| Job9|    Distributo|     Failed|2009-09-22|2015-11-17|\n",
      "|Job10| AndersonSquad|     Failed|2000-04-10|2014-09-15|\n",
      "|Job11|    Distributo|  Completed|2020-10-16|2018-10-27|\n",
      "|Job12| AndersonSquad|     Failed|2017-08-21|2017-12-20|\n",
      "|Job13|MindOvermatter|     Failed|2002-05-18|2014-12-23|\n",
      "|Job14|    Distributo|In Progress|2010-04-16|      NULL|\n",
      "|Job15| AndersonSquad|  Completed|2001-06-16|2021-02-19|\n",
      "|Job16|    Distributo|  Completed|2021-08-14|2020-04-21|\n",
      "|Job17|      JuiceBox|  Completed|2008-05-13|2007-07-24|\n",
      "|Job18|    Distributo|     Failed|2002-06-12|2017-05-17|\n",
      "|Job19|MindOvermatter|    Pending|2016-03-21|      NULL|\n",
      "|Job20|    Distributo|    Pending|2019-12-26|      NULL|\n",
      "+-----+--------------+-----------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"jobs_data.csv\", header=True, inferSchema=True)\n",
    "print(df.head)\n",
    "print(df.columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Completed, Count: 125186\n",
      "Status: In Progress, Count: 124948\n",
      "Status: Failed, Count: 124721\n",
      "Status: Pending, Count: 125145\n"
     ]
    }
   ],
   "source": [
    "# retrieve total statuses\n",
    "helper.get_status_counts(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250093"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper.count_pending_in_progress_jobs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+-------+----------+----------+\n",
      "|jobId|   sendingTeam| status| startDate|   endDate|\n",
      "+-----+--------------+-------+----------+----------+\n",
      "| Job6| AndersonSquad|Pending|2007-07-23|2015-12-02|\n",
      "| Job7|      JuiceBox|Pending|2019-01-03|2003-12-07|\n",
      "| Job9|    Distributo|Pending|2009-09-22|2015-11-17|\n",
      "|Job10| AndersonSquad|Pending|2000-04-10|2014-09-15|\n",
      "|Job12| AndersonSquad|Pending|2017-08-21|2017-12-20|\n",
      "|Job13|MindOvermatter|Pending|2002-05-18|2014-12-23|\n",
      "|Job18|    Distributo|Pending|2002-06-12|2017-05-17|\n",
      "|Job27|MindOvermatter|Pending|2011-04-09|2020-12-24|\n",
      "|Job37| AndersonSquad|Pending|2020-12-12|2010-09-16|\n",
      "|Job42|      JuiceBox|Pending|2003-01-25|2000-06-14|\n",
      "|Job46|MindOvermatter|Pending|2007-12-07|2007-11-22|\n",
      "|Job52|    Distributo|Pending|2015-06-16|2003-07-17|\n",
      "|Job54|MindOvermatter|Pending|2014-12-01|2006-03-22|\n",
      "|Job55| AndersonSquad|Pending|2001-06-29|2014-08-14|\n",
      "|Job56|      JuiceBox|Pending|2021-01-18|2021-01-02|\n",
      "|Job57|      JuiceBox|Pending|2017-10-13|2007-05-01|\n",
      "|Job58|    Distributo|Pending|2021-06-05|2010-03-16|\n",
      "|Job61|MindOvermatter|Pending|2005-11-22|2015-10-26|\n",
      "|Job65|    Distributo|Pending|2000-03-23|2013-02-19|\n",
      "|Job69|      JuiceBox|Pending|2012-11-20|2020-07-10|\n",
      "+-----+--------------+-------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df = helper.retry_failed_jobs(helper.get_failed_jobs(df))\n",
    "new_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+\n",
      "|   sendingTeam| count|\n",
      "+--------------+------+\n",
      "|MindOvermatter|124579|\n",
      "| AndersonSquad|125375|\n",
      "|    Distributo|125272|\n",
      "|      JuiceBox|124774|\n",
      "+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "team_counts = helper.count_jobs_by_team(df)\n",
    "team_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 70:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "|     status|    avg(duration)|\n",
      "+-----------+-----------------+\n",
      "|  Completed|9.948133177831387|\n",
      "|In Progress|             NULL|\n",
      "|     Failed|5.749841646555111|\n",
      "|    Pending|             NULL|\n",
      "+-----------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "average_durations = helper.average_duration_by_status(df)\n",
    "average_durations.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+---------+----------+----------+\n",
      "|  jobId|   sendingTeam|   status| startDate|   endDate|\n",
      "+-------+--------------+---------+----------+----------+\n",
      "|  Job16|    Distributo|Completed|2021-08-14|2020-04-21|\n",
      "| Job307|MindOvermatter|Completed|2015-07-18|2020-08-13|\n",
      "| Job386|      JuiceBox|Completed|2002-11-02|2020-08-26|\n",
      "| Job398|    Distributo|Completed|2008-06-06|2020-03-29|\n",
      "| Job400|      JuiceBox|Completed|2015-01-15|2020-05-21|\n",
      "| Job490| AndersonSquad|Completed|2003-07-19|2020-02-08|\n",
      "| Job515| AndersonSquad|Completed|2011-04-09|2020-05-12|\n",
      "| Job518|      JuiceBox|Completed|2022-05-01|2020-11-05|\n",
      "| Job559| AndersonSquad|Completed|2008-10-03|2020-06-19|\n",
      "| Job601|    Distributo|Completed|2023-09-13|2020-04-20|\n",
      "| Job897| AndersonSquad|Completed|2007-11-28|2020-08-11|\n",
      "|Job1108| AndersonSquad|Completed|2022-07-09|2020-04-23|\n",
      "|Job1134|      JuiceBox|Completed|2009-03-07|2020-10-19|\n",
      "|Job1340|    Distributo|Completed|2007-05-13|2020-06-01|\n",
      "|Job1456| AndersonSquad|Completed|2000-05-26|2020-07-11|\n",
      "|Job1747|MindOvermatter|Completed|2011-10-10|2020-05-17|\n",
      "|Job1769|      JuiceBox|Completed|2014-08-16|2020-06-21|\n",
      "|Job1927|MindOvermatter|Completed|2006-03-08|2020-04-02|\n",
      "|Job1939|    Distributo|Completed|2023-08-24|2020-01-30|\n",
      "|Job1975| AndersonSquad|Completed|2003-12-03|2020-08-14|\n",
      "+-------+--------------+---------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "completed_jobs = helper.jobs_completed_in_range(df, \"2020-01-01\", \"2021-01-01\")\n",
    "completed_jobs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+-----+\n",
      "|   sendingTeam|     status|count|\n",
      "+--------------+-----------+-----+\n",
      "| AndersonSquad|    Pending|31415|\n",
      "|    Distributo|     Failed|31369|\n",
      "| AndersonSquad|  Completed|31359|\n",
      "|MindOvermatter|    Pending|31229|\n",
      "|MindOvermatter|In Progress|31308|\n",
      "| AndersonSquad|     Failed|31074|\n",
      "|    Distributo|    Pending|31268|\n",
      "|    Distributo|  Completed|31484|\n",
      "|      JuiceBox|  Completed|31440|\n",
      "|MindOvermatter|  Completed|30903|\n",
      "|      JuiceBox|In Progress|30962|\n",
      "|MindOvermatter|     Failed|31139|\n",
      "|      JuiceBox|     Failed|31139|\n",
      "|    Distributo|In Progress|31151|\n",
      "| AndersonSquad|In Progress|31527|\n",
      "|      JuiceBox|    Pending|31233|\n",
      "+--------------+-----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "status_distribution = helper.status_distribution_by_team(df)\n",
    "status_distribution.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,md,py"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
